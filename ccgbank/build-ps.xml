<!--
 Copyright (C) 2011-12 Michael White, Dennis N. Mehay
 
 This library is free software; you can redistribute it and/or
 modify it under the terms of the GNU Lesser General Public
 License as published by the Free Software Foundation; either
 version 2.1 of the License, or (at your option) any later version.
 
 This library is distributed in the hope that it will be useful,
 but WITHOUT ANY WARRANTY; without even the implied warranty of
 MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 GNU Lesser General Public License for more details.
 
 You should have received a copy of the GNU Lesser General Public
 License along with this program; if not, write to the Free Software
 Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
-->

<!-- This build file is for parsing models using the converted CCGbank. -->

<!-- $Id: build-ps.xml,v 1.16 2011/12/13 07:20:09 mwhite14850 Exp $ -->
<project name="CCGbankParserModels" default="all" basedir=".">
  
  <taskdef resource="net/sf/antcontrib/antlib.xml"/>
  <property file="build.properties"/>
  <property file="build-models.properties"/>
  <property file="build-st.properties"/>
  <property file="build-ps.properties"/>


  <!-- =================================================================== -->
  <!-- Initialization target                                               -->
  <!-- =================================================================== -->
  <target name="init">
    <tstamp/>
    <!-- initial parser dependencies -->
    <uptodate targetfile="${deriv.factors.train}" srcfile="${test.dir}/02/wsj_0201.xml" property="deriv.factors.train.uptodate"/>
  </target>


  <!-- =================================================================== -->
  <!-- Parser                                                              -->
  <!-- =================================================================== -->

  <target name="get-deriv-factors-train" depends="init" unless="deriv.factors.train.uptodate">
    <for list="${training.dirs}" param="sect">
      <sequential>
	<echo>Extracting derivation factors for section @{sect}</echo>
	<exec executable="ccg-test" dir="." output="${log.dir}/log.extract.derivs.@{sect}">
	  <arg value="-derivf"/> <arg value="${parser.feats.dir}/deriv-factors-@{sect}"/>
	  <arg value="-g"/> <arg value="${extract.dir}/grammar.xml"/>
	  <arg value="${test.dir}/@{sect}"/>
	</exec>
      </sequential>
    </for>
    <echo>Concatenating training derivation factors to ${deriv.factors.train}</echo>
    <concat destfile="${deriv.factors.train}">
      <fileset dir="${parser.feats.dir}" includes="deriv-factors-*" excludes="deriv-factors-00,deriv-factors-23"/>
    </concat>
  </target>

  <target name="check-parser-vocab" depends="init">
    <uptodate targetfile="${vocab.parser.train}" srcfile="${deriv.factors.train}" property="vocab.parser.train.uptodate"/>
  </target>

  <target name="get-parser-vocab" depends="get-deriv-factors-train,check-parser-vocab" unless="vocab.parser.train.uptodate">
    <echo message="Writing counts from factor file"/>
    <exec executable="fngram-count" dir="${parser.models.dir}">
      <arg value="-text"/> <arg value="${basedir}/${deriv.factors.train}"/> 
      <arg line="-factor-file vocab.flm -write-counts -sort"/>
    </exec>
    <for list="w,wt,ws,e,h,p,cp,ct,tt,t,s,cs,ts" param="F">
      <sequential>
	<exec executable="cut" dir="${parser.models.dir}" output="${parser.models.dir}/uni.count">
	  <arg line="-f 2,3 @{F}.count"/>
	</exec>
	<move file="${parser.models.dir}/uni.count" tofile="${parser.models.dir}/@{F}.count"/>
      </sequential>
    </for>
    <echo message="Writing vocab with frequency cutoffs"/>
    <concat destfile="${parser.models.dir}/min20.count">
      <filelist dir="${parser.models.dir}" files="w.count,wt.count,ws.count"/>
    </concat>
    <concat destfile="${parser.models.dir}/min10.count">
      <filelist dir="${parser.models.dir}" files="e.count,h.count,p.count,cp.count,ct.count,tt.count,t.count,s.count,cs.count,ts.count"/>
    </concat>
    <exec executable="ngram-count" dir="${parser.models.dir}">
      <arg line="-read min20.count -gt1min 20 -write-vocab vocab.min20 -read-with-mincounts -sort"/>
    </exec>
    <exec executable="ngram-count" dir="${parser.models.dir}">
      <arg line="-read min10.count -gt1min ${catfreq.cutoff} -write-vocab vocab.min10 -read-with-mincounts -sort"/>
    </exec>
    <concat destfile="${vocab.parser.train}">
      <filelist dir="${parser.models.dir}" files="vocab.min20,vocab.min10"/>
    </concat>
    <delete>
      <fileset dir="${parser.models.dir}" includes="*.count,vocab.min20,vocab.min10"/>
    </delete>
  </target>

  <target name="check-parser-flms" depends="init">
    <uptodate targetfile="${parser.models.dir}/ct_p0.lm" srcfile="${vocab.parser.train}" property="parser.flms.uptodate"/>
  </target>

  <target name="make-parser-flms" depends="get-parser-vocab,check-parser-flms" unless="parser.flms.uptodate">
    <for list="top,leaf,unary,binary" param="F">
      <sequential>
	<echo message="Making gen syn language models using ${parser.models.dir}/@{F}.flm"/>
	<exec executable="fngram-count" dir="${parser.models.dir}">
	  <arg value="-text"/> <arg value="${basedir}/${deriv.factors.train}"/> 
	  <arg line="-factor-file @{F}.flm -vocab vocab.parser.train -lm -unk -write-counts -nonull"/>
	  <arg line="-no-virtual-begin-sentence -no-virtual-end-sentence"/>
	  <arg line="-no-add-start-sentence-token -no-add-end-sentence-token"/>
	</exec>
      </sequential>
    </for>
    <delete>
      <fileset dir="${parser.models.dir}" includes="*.count"/>
    </delete>
  </target>

  <target name="copy-train-grammar" depends="init">
    <echo>Copying train grammar with cutoffs to ${extract.dir}</echo>
    <copy todir="${extract.dir}" overwrite="true">
      <fileset dir="${grams.dir}/train-cfc10" includes="*.xml,*.html"/>
    </copy>
  </target>

  <target name="copy-dev-morph" depends="copy-train-grammar">
    <echo>Copying dev morph to ${extract.dir}</echo>
    <copy tofile="${extract.dir}/morph.xml" file="${grams.dir}/dev/morph.xml" overwrite="true"/>
  </target>

  <target name="test-parser" depends="copy-dev-morph">
    <echo>Loading parse.prefs</echo>
    <exec executable="tccg" dir="${parser.models.dir}">
      <arg line="-importprefs parse.prefs"/>
    </exec>
    <echo>Parsing dev section to ${log.dir}/parse.dev.log</echo>
    <exec executable="ccg-test" dir="${basedir}" output="${log.dir}/parse.dev.log">
      <arg value="-norealization"/>
      <arg value="-g"/> <arg value="${extract.dir}/grammar.xml"/>
      <arg value="-stconfig"/> <arg value="${supertagger.models.dir}/st.config"/>
      <arg value="-parsescorer"/> <arg value="plugins.MyGenSynScorer"/>
      <arg value="${test.dir}/00"/>
    </exec>
  </target>



  <!-- =================================================================== -->
  <!-- Parser Perceptron Model                                             -->
  <!-- =================================================================== -->

  <target name="check-parser-flms-excl-sect" depends="init">
    <uptodate targetfile="${parser.models.dir}/excl02/ct_p0.lm" 
	      srcfile="${vocab.parser.train}" property="parser.flms.excl.sect.uptodate"/>
  </target>

  <!-- train models excluding each section in turn -->
  <target name="make-parser-flms-excl-sect" 
	  depends="get-parser-vocab,check-parser-flms-excl-sect" unless="parser.flms.excl.sect.uptodate">
    <for list="${training.dirs}" param="sect">
      <sequential>
	<echo>Concatenating training derivation factors excluding sect @{sect} to ${deriv.factors.train}.excl@{sect}</echo>
	<concat destfile="${deriv.factors.train}.excl@{sect}">
	  <fileset dir="${parser.feats.dir}" includes="deriv-factors-*" 
		   excludes="deriv-factors-@{sect},deriv-factors-00,deriv-factors-23"/>
	</concat>
	<echo>Copying flm files to ${parser.models.dir}/excl@{sect}</echo>
	<copy todir="${parser.models.dir}/excl@{sect}" overwrite="true">
	  <fileset dir="${parser.models.dir}" includes="*.flm"/>
	</copy>
	<for list="top,leaf,unary,binary" param="F">
	  <sequential>
	    <echo message="Making gen syn language models using ${parser.models.dir}/excl@{sect}/@{F}.flm"/>
	    <exec executable="fngram-count" dir="${parser.models.dir}/excl@{sect}">
	      <arg value="-text"/> <arg value="${basedir}/${deriv.factors.train}.excl@{sect}"/> 
	      <arg line="-factor-file @{F}.flm -vocab ../vocab.parser.train -lm -unk -write-counts -nonull"/>
	      <arg line="-no-virtual-begin-sentence -no-virtual-end-sentence"/>
	      <arg line="-no-add-start-sentence-token -no-add-end-sentence-token"/>
	    </exec>
	  </sequential>
	</for>
	<delete>
	  <fileset dir="${parser.models.dir}/excl@{sect}" includes="*.count"/>
	  <fileset file="${deriv.factors.train}.excl@{sect}"/>
	</delete>
      </sequential>
    </for>
  </target>

  <!-- generate parser events for each section -->
  <macrodef name="gen-parser-events-for-sect">
    <attribute name="sect"/>
    <sequential>
      <echo>Generating parser training events for sect @{sect}</echo>
      <echo>Copying train grammar with to ${extract.dir}</echo>
      <copy todir="${extract.dir}" overwrite="true">
	<fileset dir="${grams.dir}/train" includes="*.xml,*.html"/>
      </copy>
      <echo>Loading gen-events.prefs</echo>
      <exec executable="tccg" dir="${parser.models.dir}">
	<arg line="-importprefs gen-events.prefs"/>
      </exec>
      <echo>Generating events to ${parser.feats.dir}/events-@{sect}.gz</echo>
      <exec executable="ccg-test" dir="${basedir}" output="${log.dir}/gen.parser.events.@{sect}.log">
	<arg value="-Dgensyn.model.dir=${parser.models.dir}/excl@{sect}"/>
	<arg value="-norealization"/>
	<arg value="-g"/> <arg value="${extract.dir}/grammar.xml"/>
	<arg value="-2events"/> <arg value="${parser.feats.dir}/events-@{sect}.gz"/>
	<arg value="-stconfig"/> <arg value="${supertagger.models.dir}/st.config.train"/>
	<arg value="-parsescorer"/> <arg value="plugins.MyGenSynScorer"/>
	<arg value="-extractor"/> <arg value="plugins.MySynSemFeatureExtractor"/>
	<arg value="${test.dir}/@{sect}"/>
      </exec>
    </sequential>
  </macrodef>

  <target name="check-parser-events" depends="init">
    <uptodate targetfile="${parser.feats.dir}/events-${sect}.gz" 
	      srcfile="${parser.models.dir}/excl02/ct_p0.lm" property="parser.events.uptodate"/>
  </target>

  <target name="gen-parser-events" 
	  depends="make-parser-flms-excl-sect,check-parser-events" unless="parser.events.uptodate">
    <gen-parser-events-for-sect sect="${sect}"/>
  </target>

  <target name="check-parser-events-train" depends="init">
    <uptodate targetfile="${parser.feats.dir}/events-02.gz" srcfile="${parser.models.dir}/excl02/ct_p0.lm" property="parser.events.train.uptodate"/>
  </target>

  <!-- see bin/gen_parser_events_* for scripts to extract events in parallel -->
  <target name="gen-parser-events-train" 
	  depends="make-parser-flms-excl-sect,check-parser-events-train" unless="parser.events.train.uptodate">
    <for list="${training.dirs}" param="sect">
      <sequential>
	<gen-parser-events-for-sect sect="@{sect}"/>
      </sequential>
    </for>
  </target>

  <target name="check-parser-events-concat" depends="init">
    <uptodate targetfile="${parser.feats.dir}/events-train.gz" 
	      srcfile="${parser.feats.dir}/events-02.gz" property="parser.events.concat.uptodate"/>
  </target>

  <target name="concat-parser-events" 
	  depends="gen-parser-events-train,check-parser-events-concat" unless="parser.events.concat.uptodate">
    <echo>Concatenating event files to ${parser.feats.dir}/events-train.gz</echo>
    <for list="${training.dirs}" param="sect">
      <sequential>
	<echo>Concatenating ${parser.feats.dir}/events-@{sect}.gz</echo>
	<gunzip src="${parser.feats.dir}/events-@{sect}.gz"/>
	<concat destfile="${parser.feats.dir}/events-train" append="true">
	  <fileset file="${parser.feats.dir}/events-@{sect}"/>
	</concat>
	<delete file="${parser.feats.dir}/events-@{sect}" quiet="true"/>
      </sequential>
    </for>
    <gzip src="${parser.feats.dir}/events-train" destfile="${parser.feats.dir}/events-train.gz"/>
    <delete file="${parser.feats.dir}/events-train" quiet="true"/>
  </target>

  <target name="check-parser-alphabet" depends="init">
    <uptodate targetfile="${parser.feats.dir}/alph.gz" 
	      srcfile="${parser.feats.dir}/events-train.gz" property="parser.alphabet.uptodate"/>
  </target>

  <target name="calc-parser-alphabet" 
	  depends="concat-parser-events,check-parser-alphabet" unless="parser.alphabet.uptodate">
    <echo>Calculating feature alphabet as ${parser.feats.dir}/alph.gz</echo>
    <java classname="opennlp.ccg.perceptron.Alphabet" output="${log.dir}/log.parser.alphabet">
      <arg value="${parser.feats.dir}/events-train.gz"/>
      <arg value="${parser.feats.dir}/alph.gz"/>
      <arg value="-p"/> <arg value="5"/>
    </java>
  </target>

  <target name="check-parser-perceptron" depends="init">
    <uptodate targetfile="${parser.models.dir}/model.gz" 
	      srcfile="${parser.feats.dir}/alph.gz" property="parser.perceptron.uptodate"/>
  </target>

  <target name="train-parser-perceptron" 
	  depends="calc-parser-alphabet,check-parser-perceptron" unless="parser.perceptron.uptodate">
    <echo>Training perceptron model to ${parser.models.dir}/model.gz</echo>
    <java classname="opennlp.ccg.perceptron.Trainer" output="${log.dir}/log.parser.perceptron">
      <arg value="${parser.feats.dir}/events-train.gz"/>
      <arg value="${parser.feats.dir}/alph.gz"/>
      <arg value="10"/>
      <arg value="${parser.models.dir}/model.gz"/>
      <arg value="-i"/> <arg value="${parser.models.dir}/model.init"/>
      <arg value="-n"/> <arg value="1"/>
    </java>
  </target>

  <target name="test-parser-perceptron" depends="copy-dev-morph">
    <echo>Loading parse.prefs</echo>
    <exec executable="tccg" dir="${parser.models.dir}">
      <arg line="-importprefs parse.prefs"/>
    </exec>
    <echo>Parsing dev section to ${log.dir}/parse.perceptron.dev.log</echo>
    <exec executable="ccg-test" dir="${basedir}" output="${log.dir}/parse.perceptron.dev.log">
      <arg value="-norealization"/>
      <arg value="-g"/> <arg value="${extract.dir}/grammar.xml"/>
      <arg value="-stconfig"/> <arg value="${supertagger.models.dir}/st.config"/>
      <arg value="-parsescorer"/> <arg value="plugins.MyParserPerceptronScorer"/>
      <arg value="${test.dir}/00"/>
    </exec>
  </target>


  <!-- =================================================================== -->
  <!-- Parsing novel data                                                  -->
  <!-- =================================================================== -->

  <target name="prepare-novel-dir" depends="init">
    <mkdir dir="${basedir}/${novel.file}.dir"/>
  </target>

  <target name="check-for-tok" depends="prepare-novel-dir">
    <uptodate targetfile="${novel.file}.dir/text.tok" srcfile="${basedir}/${novel.file}" property="text.tok.uptodate"/>
  </target>

  <target name="prepare-novel-text" depends="check-for-tok" unless="text.tok.uptodate">
    <!-- We brute-force a java task with <exec...>...</exec>, since -->
    <!-- for some reason <java> tasks only work for OpenCCG java (?)-->
    <!-- First tokenize -->
    <exec executable="java" dir="${basedir}" output="${novel.file}.dir/text.tok" error="${novel.file}.dir/errlog">
      <arg value="-Dfile.encoding=UTF8"/>
      <arg value="-cp"/> <arg value="${stanford.core.nlp.jar}"/>
      <arg value="edu.stanford.nlp.process.PTBTokenizer"/>
      <arg value="-preserveLines"/> 
      <arg value="-options"/> 
      <arg value="untokenizable=noneKeep,latexQuotes=true,normalizeCurrency=false,normalizeParentheses=true,normalizeOtherBrackets=true,ptb3Ellipsis=true,ptb3Dashes=true,strictTreebank3=false"/>
      <arg value="${basedir}/${novel.file}"/>
    </exec>
    <!-- This takes "American"-style attributive quotations to "British"/"logical" style. -->
    <exec executable="python" dir="${basedir}" input="${novel.file}.dir/text.tok" output="${novel.file}.dir/text" error="${novel.file}.dir/errlog">
      <arg value="./bin/american-to-logical-quotes.py"/>
    </exec>
  </target>

  <target name="copy-train-grammar-novel" depends="prepare-novel-dir">
    <echo>Copying training grammar with cutoffs and other miscellanea to ${novel.file}.dir/extract/</echo>
    <copy todir="${novel.file}.dir/extract/" overwrite="true">
      <fileset dir="${grams.dir}/train-cfc10" includes="*.xml,*.xsl"/>
    </copy>
    <copy todir="${novel.file}.dir/extract/" overwrite="true">
      <fileset dir="${extract.dir}" includes="*.xsl"/>
    </copy>
    <copy todir="${novel.file}.dir/extract/info/" file="${extract.dir}/info/combos-train" overwrite="true"/>
  </target>

  <!-- Prepare for further processing by truecasing -->
  <target name="check-truecased-text" depends="prepare-novel-text">
    <uptodate targetfile="${novel.file}.dir/truecased-text" srcfile="${novel.file}.dir/text" property="truecased.text.uptodate"/>
  </target>

  <target name="truecase-text" depends="check-truecased-text" unless="truecased.text.uptodate">
    <echo message="Truecasing text for NER tagging into file ${novel.file}.dir/truecased-text"/>
    <java classname="opennlp.ccg.lexicon.TrueCaser" input="${novel.file}.dir/text" output="${novel.file}.dir/truecased-text">
      <arg value="-t"/> <arg value="${truecase.list}"/>
      <arg value="-r"/> <arg value="${titlecase.threshold}"/>
    </java>
  </target>

  <target name="check-for-ner" depends="truecase-text">
    <uptodate targetfile="${novel.file}.dir/nertext" srcfile="${novel.file}.dir/truecased-text" property="ner.text.uptodate"/>
  </target>

  <!-- NER tag with Stanford NE tagger. See docs/ccgbank-README for installation instructions, -->
  <!-- and build-ps.properties for NE-related properties. -->
  <target name="ner-tag-text" depends="check-for-ner" unless="ner.text.uptodate">
    <echo message="NER tagging into file ${novel.file}.dir/nertext"/>
    <echo message="Models: ${ner.model1}, ${ner.model2}, ${ner.model3}"/>
    <java classname="nerapp.NERApp" classpath="bin/ner/NERApp.jar:${stanford.core.nlp.jar}" error="${novel.file}.dir/tmplogf">
      <arg value="${novel.file}.dir/truecased-text"/> 
      <arg value="${novel.file}.dir/nertext.raw"/>
      <arg value="${ner.model1}"/> <arg value="${ner.model2}"/> <arg value="${ner.model3}"/>
    </java>
    <exec executable="python" input="${novel.file}.dir/nertext.raw" output="${novel.file}.dir/nertext" error="${novel.file}.dir/tmplogf">
      <arg value="bin/ner/post-process-stanford-ner.py"/>
    </exec>
    <delete file="${novel.file}.dir/tmplogf" quiet="true"/>
  </target>

  <!-- get just the words (not NE labels) for POS tagging -->
  <target name="check-for-pos-prep" depends="ner-tag-text">
    <uptodate targetfile="${novel.file}.dir/nertext-nolabs" srcfile="${novel.file}.dir/nertext" property="pos.prep.uptodate"/>
  </target>

  <target name="postag-prep" depends="check-for-pos-prep" unless="pos.prep.uptodate">
    <!-- nb: using output file here and input file in next step seems to help ensure 
	 file is ready for reading (ant bug?) -->
    <exec executable="python" input="${novel.file}.dir/nertext">
      <arg value="bin/get_just_words_from_ner_text.py"/>
      <arg value="-o"/> <arg value="${novel.file}.dir/nertext-nolabs"/>
    </exec>
  </target>

  <!-- POS tag -->
  <target name="check-novel-pos-tags"  depends="postag-prep">
    <uptodate targetfile="${novel.file}.dir/pos" srcfile="${novel.file}.dir/nertext-nolabs" property="pos.uptodate"/>
  </target>

  <!-- postag fused NE tokens (without labels) using true-cased POS tagger. -->
  <target name="postag-novel" depends="check-novel-pos-tags" unless="pos.uptodate">
    <echo message="POS tagging novel sentences to ${novel.file}.dir/pos"/>
    <java classname="opennlp.ccg.parse.postagger.BasicPOSTagger">
      <arg value="-i"/> <arg value="${novel.file}.dir/nertext-nolabs"/>
      <arg value="-o"/> <arg value="${novel.file}.dir/pos"/>
      <arg value="-c"/> <arg value="${supertagger.models.dir}/pos.config"/>
    </java>
  </target>

  <!-- rejoin pos-tagged words and NE labels for making the novel morph file -->
  <target name="check-merged-ne-pos" depends="postag-novel">
    <uptodate targetfile="${novel.file}.dir/pairs" srcfile="${novel.file}.dir/pos" property="check.merged.ne.pos.uptodate"/>
  </target>

  <target name="merge-ne-pos" depends="check-merged-ne-pos" unless="check.merged.ne.pos.uptodate">
    <echo message="Merging POS-tagged words and NE-labelled words for morph file creation"/>
    <exec executable="python" dir="${basedir}" output="${novel.file}.dir/pairs">
      <arg value="bin/merge_pos_ne.py"/> 
      <arg value="-p"/> 
      <arg value="${novel.file}.dir/pos"/> <arg value="-n"/> <arg value="${novel.file}.dir/nertext"/>
    </exec>
  </target>

  <target name="check-novel-morph-xml" depends="merge-ne-pos">
    <uptodate targetfile="${novel.file}.dir/morph.xml" srcfile="${novel.file}.dir/pairs" property="novel.morph.uptodate"/>
  </target>

  <target name="make-novel-morph-xml" depends="check-novel-morph-xml" unless="novel.morph.uptodate">
    <echo message="Sorting and stemming to ${novel.file}.dir/morph"/>
    <exec executable="python" input="${novel.file}.dir/pairs" dir="${basedir}"
	  output="${novel.file}.dir/morph.input"
	  error="${novel.file}.dir/tmplogf">
      <arg value="bin/prepare-for-stanford-morpha.py"/>
    </exec>
    <!-- The following doesn't work for some reason having to do with
    ant, so we brute-force the equivalent with an 'exec' task below. 
    -->
    <!--
    <java classname="edu.stanford.nlp.process.Morphology"
    output="${novel.file}.dir/morph"
    classpath="${stanford.core.nlp.jar}" error="${novel.file}.dir/errlog">
      <arg value="${novel.file}.dir/morph.input"/>
    </java>
    -->
    <exec executable="java" dir="${basedir}" output="${novel.file}.dir/morph" error="${novel.file}.dir/errlog">
      <arg value="-Dfile.encoding=UTF8"/>
      <arg value="-cp"/> <arg value="${stanford.core.nlp.jar}"/>
      <arg value="edu.stanford.nlp.process.Morphology"/> <arg value="${novel.file}.dir/morph.input"/>
    </exec>
    <!-- this next step sort/uniq's and merges. -->
    <exec executable="python" dir="${basedir}"
	  output="${novel.file}.dir/morph.xml"
	  error="${novel.file}.dir/tmplogf">
      <arg value="bin/merge-stanford-morpha-with-pos.py"/>
      <arg value="-m"/> <arg value="${novel.file}.dir/morph"/>
      <arg value="-p"/> <arg value="${novel.file}.dir/pairs"/>
    </exec>
    <delete file="${novel.file}.dir/errlogf" quiet="true"/>
    <delete file="${novel.file}.dir/tmplogf" quiet="true"/>
  </target>

  <target name="merge-novel-morph-xml" depends="make-novel-morph-xml,copy-train-grammar-novel">
    <echo>Merging training morph (with cutoffs) and novel morph to ${novel.file}.dir/extract/morph.xml</echo>
    <xslt style="templates/mergeMorph.xsl" basedir="${convert.dir}" force="true"
	  in="${grams.dir}/train-cfc10/morph.xml" out="${novel.file}.dir/extract/morph.xml">
      <factory name="org.apache.xalan.processor.TransformerFactoryImpl"/>
      <param name="newmorphfile" expression="../${novel.file}.dir/morph.xml"/>
    </xslt>
  </target>

  <target name="check-test-parser-novel-nbest" depends="merge-novel-morph-xml">
    <uptodate targetfile="${novel.file}.dir/tb.xml" srcfile="${novel.file}.dir/morph.xml" property="check-test-parser-novel-nbest.uptodate"/>
  </target>

  <target name="test-parser-novel-nbest" depends="check-test-parser-novel-nbest" unless="check-test-parser-novel-nbest.uptodate">
    <echo>Loading parse.prefs</echo>
    <java classname="opennlp.ccg.TextCCG">
      <arg value="-importprefs"/> <arg value="${parser.models.dir}/parse.prefs"/>
    </java>
    <echo>Parsing ${novel.file}.dir/nertext-nolabs to ${novel.file}.dir/tb.xml</echo>
    <java classname="opennlp.ccg.Parse" output="${novel.file}.dir/parse.log">
      <arg value="-g"/> <arg value="${novel.file}.dir/extract/grammar.xml"/>
      <arg value="-stconfig"/> <arg value="${supertagger.models.dir}/st.config"/>
      <arg value="-parsescorer"/> <arg value="plugins.MyGenSynScorer"/>
      <arg value="${novel.file}.dir/nertext-nolabs"/>
      <arg value="${novel.file}.dir/tb.xml"/>
      <arg value="-nbestListSize"/> <arg value="${nbest.list.size}"/>
      <arg value="-includederivs"/>
      <arg value="-includescores"/>
    </java>
  </target>

  <target name="check-test-parser-novel" depends="merge-novel-morph-xml">
    <uptodate targetfile="${novel.file}.dir/tb.xml" srcfile="${novel.file}.dir/morph.xml" property="check-test-parser-novel.uptodate"/>
  </target>

  <target name="test-parser-novel" depends="check-test-parser-novel" unless="check-test-parser-novel.uptodate">
    <echo>Loading parse.prefs</echo>
    <java classname="opennlp.ccg.TextCCG">
      <arg value="-importprefs"/> <arg value="${parser.models.dir}/parse.prefs"/>
    </java>
    <echo>Parsing ${novel.file}.dir/nertext-nolabs to ${novel.file}.dir/tb.xml</echo>
    <java classname="opennlp.ccg.Parse" output="${novel.file}.dir/parse.log">
      <arg value="-g"/> <arg value="${novel.file}.dir/extract/grammar.xml"/>
      <arg value="-stconfig"/> <arg value="${supertagger.models.dir}/st.config"/>
      <arg value="-parsescorer"/> <arg value="plugins.MyGenSynScorer"/>
      <arg value="${novel.file}.dir/nertext-nolabs"/>
      <arg value="${novel.file}.dir/tb.xml"/>
    </java>
  </target>

  <!-- =================================================================== -->
  <!-- Top-level                                                           -->
  <!-- 1st: run all                                                        -->
  <!-- 2nd: run bin/gen_parser_events_* to extract events in parallel      -->
  <!-- 3rd: run train-parser-perceptron                                    -->
  <!-- =================================================================== -->

  <target name="all" depends="make-parser-flms,make-parser-flms-excl-sect"/>
  <target name="train-perceptron" depends="train-parser-perceptron"/>
  <target name="test" depends="test-parser"/>
  <target name="test-perceptron" depends="test-parser-perceptron"/>
  <target name="test-novel" depends="test-parser-novel"/>

</project>
